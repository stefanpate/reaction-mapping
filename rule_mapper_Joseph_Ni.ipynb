{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import copy\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# bunch of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MapRules:\n",
    "    \"\"\"Map intended reactants to database reactants described by the same reaction operators.\"\"\"\n",
    "\n",
    "    def __init__(self, atom_mapping_path=None, rules_path=None, molfiles_path=None, seed_dict=None,\n",
    "                 cofactor_list_path=None, cofactor_pair_path=None, cofactors=True, start_name=None, start_smiles=None):\n",
    "        self.atom_mapping_path = atom_mapping_path\n",
    "        self.rules = pd.read_csv(rules_path, sep='\\t', index_col=0)\n",
    "        self.molfiles_path = molfiles_path\n",
    "        if self.atom_mapping_path:\n",
    "            self.reaction_df = self._create_metacyc_info(self.atom_mapping_path)\n",
    "        if cofactors:\n",
    "            self.cofactor_name_dict, self.cofactor_list_dict, self.cofactor_pair_dict = get_cofactors(cofactor_list_path, cofactor_pair_path)\n",
    "        else:\n",
    "            self.cofactor_name_dict = {}\n",
    "            self.cofactor_list_dict = {}\n",
    "            self.cofactor_pair_dict = {}\n",
    "        self.seed_dict = seed_dict\n",
    "        if start_name:\n",
    "            self.start_name = start_name\n",
    "        if start_smiles:\n",
    "            self.start_smiles = start_smiles\n",
    "\n",
    "    def _create_metacyc_info(self, atom_mapping_path):\n",
    "        \"\"\"Read metacyc atom mapping information and return as a dataframe, also takes in reaction.dat information\"\"\"\n",
    "\n",
    "        # read reactions.dat, group info for each reaction\n",
    "        with open(atom_mapping_path, 'r') as file:\n",
    "            reactions = file.read().split('//')\n",
    "\n",
    "        # read reactions.dat info for each reaction\n",
    "        info_df = pd.DataFrame()\n",
    "\n",
    "        for entry in reactions:\n",
    "\n",
    "            # storing info for this reaction\n",
    "            info_dict = {}\n",
    "\n",
    "            # for each line\n",
    "            lines = entry.split('\\n')\n",
    "            for line in lines:\n",
    "                try:\n",
    "                    line = line.split(' - ', 1)\n",
    "                    if (line[0] not in info_dict) & (line[1] != 'PROTON') & (line[1] != '|Acceptor|') \\\n",
    "                            & (line[1] != '|Donor-H2|') & (line[1] != '|ETR-Quinones|') & (line[1] != '|ETR-Quinols|'):\n",
    "                        # if left or right in atom-mappings\n",
    "                        if line[0] == 'LEFT' or line[0] == 'RIGHT':\n",
    "                            try:\n",
    "                                if line[1] + ' ' in info_dict['ATOM-MAPPINGS']:\n",
    "                                    info_dict[line[0]] = line[1]\n",
    "                            except KeyError:\n",
    "                                pass\n",
    "                        else:\n",
    "                            info_dict[line[0]] = line[1]\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "            # process reaction information\n",
    "            try:\n",
    "                unique_id = info_dict['UNIQUE-ID']\n",
    "            except KeyError:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                reaction_direction = info_dict['REACTION-DIRECTION'].replace('PHYSIOL-', '').replace('IRREVERSIBLE-',\n",
    "                                                                                                     '')\n",
    "                left = info_dict['LEFT'].lstrip('|').rstrip('|') + ' '\n",
    "                right = info_dict['RIGHT'].lstrip('|').rstrip('|') + ' '\n",
    "            except KeyError:\n",
    "                reaction_direction = ''\n",
    "                left = ''\n",
    "                right = ''\n",
    "\n",
    "            try:\n",
    "                ec = info_dict['EC-NUMBER'].lstrip('EC-')\n",
    "            except KeyError:\n",
    "                ec = ''\n",
    "\n",
    "            # add information to info_df\n",
    "            info_add = pd.DataFrame([left, right, reaction_direction, ec], index=['Left', 'Right', 'Direction', 'EC'],\n",
    "                                    columns=[unique_id])\n",
    "            info_df = pd.concat([info_df, info_add], axis=1, sort=True)\n",
    "\n",
    "        # read atom mapping, group info for each reaction\n",
    "        with open(atom_mapping_path, 'r') as file:\n",
    "            metacyc = file.read().split('//')\n",
    "\n",
    "        # read atom mapping info for each reaction\n",
    "        reaction_df = pd.DataFrame()\n",
    "        for entry in metacyc:\n",
    "\n",
    "            # storing info for this reaction\n",
    "            reaction_dict = {}\n",
    "\n",
    "            # for each line\n",
    "            lines = entry.split('\\n')\n",
    "            for line in lines:\n",
    "                try:\n",
    "                    line = line.split(' - ', 1)\n",
    "                    reaction_dict[line[0]] = line[1]\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "            # solve for MetaCyc 19.0 ((\n",
    "            try:\n",
    "                am = reaction_dict['ATOM-MAPPINGS'].lstrip('(').split('(')\n",
    "                am = '('.join(am[1:])\n",
    "\n",
    "                if not am:  # skip if no am\n",
    "                    continue\n",
    "\n",
    "                # parse am, reactants, products\n",
    "                temp = am.split(')) ((')\n",
    "                product_temp = '(' + temp[1].rstrip(')') + ')'\n",
    "\n",
    "                temp = temp[0].split(') (')\n",
    "                am_temp = temp[0]\n",
    "                reactant_temp = '(' + ') ('.join(temp[1:]).replace('(', '', 1).replace('(', '', 1) + ')'\n",
    "\n",
    "                # duplicate mols\n",
    "                if '((' in reactant_temp:  # reactant side\n",
    "                    name_edit = reactant_temp\n",
    "                    name_edit = name_edit.split('((')\n",
    "\n",
    "                    for i in range(1, len(name_edit)):  # edit each duplicate mol\n",
    "                        name_edit[i] = name_edit[i].replace(' ', ':', 1).replace(')', '', 1)\n",
    "\n",
    "                    reactant_temp = '('.join(name_edit)\n",
    "\n",
    "                if '((' in product_temp:  # product side\n",
    "                    name_edit = product_temp\n",
    "                    name_edit = name_edit.split('((')\n",
    "\n",
    "                    for i in range(1, len(name_edit)):  # edit each duplicate mol\n",
    "                        name_edit[i] = name_edit[i].replace(' ', ':', 1).replace(')', '', 1)\n",
    "\n",
    "                    product_temp = '('.join(name_edit)\n",
    "\n",
    "                reactant_temp = ''.join(re.findall(r'[A-Za-z0-9_:()\\- ]', reactant_temp))\n",
    "                product_temp = ''.join(re.findall(r'[A-Za-z0-9_:()\\- ]', product_temp))\n",
    "\n",
    "            except KeyError:\n",
    "                continue\n",
    "\n",
    "            # determine if UNIQUE-ID in atom-mapping is in reactions.dat\n",
    "            try:\n",
    "                info_dict = info_df[reaction_dict['UNIQUE-ID']]\n",
    "            except KeyError:\n",
    "                direction = '+-'\n",
    "                ec = ''\n",
    "                reaction_add = pd.DataFrame(\n",
    "                    [reactant_temp, product_temp, am_temp, direction, ec],\n",
    "                    index=['Reactants', 'Products', 'AM', 'Direction', 'EC'], columns=[reaction_dict['UNIQUE-ID']])\n",
    "                reaction_df = pd.concat([reaction_df, reaction_add], axis=1, sort=True)\n",
    "                continue\n",
    "\n",
    "            # process direction info\n",
    "            direction = info_dict.Direction\n",
    "            ec = info_dict.EC\n",
    "\n",
    "            if direction != '':  # if direction info is provided\n",
    "                if direction == 'REVERSIBLE':  # if reversible\n",
    "                    direction = '+-'\n",
    "                elif direction == 'LEFT-TO-RIGHT':  # if left to right\n",
    "                    if (info_dict.Left in reactant_temp) & (info_dict.Right in product_temp):\n",
    "                        direction = '+'\n",
    "                    elif (info_dict.Right in reactant_temp) & (info_dict.Left in product_temp):\n",
    "                        direction = '-'\n",
    "                elif direction == 'RIGHT-TO-LEFT':  # if right to left\n",
    "                    if (info_dict.Left in reactant_temp) & (info_dict.Right in product_temp):\n",
    "                        direction = '-'\n",
    "                    elif (info_dict.Right in reactant_temp) & (info_dict.Left in product_temp):\n",
    "                        direction = '+'\n",
    "                else:\n",
    "                    direction = '+-'\n",
    "            else:  # if direction info not provided, default reversible\n",
    "                direction = '+-'\n",
    "\n",
    "            reaction_add = pd.DataFrame(\n",
    "                [reactant_temp, product_temp, am_temp, direction, ec],\n",
    "                index=['Reactants', 'Products', 'AM', 'Direction', 'EC'], columns=[reaction_dict['UNIQUE-ID']])\n",
    "            reaction_df = pd.concat([reaction_df, reaction_add], axis=1, sort=True)\n",
    "\n",
    "        print('Finished reading MetaCyc information.')\n",
    "\n",
    "        return reaction_df\n",
    "\n",
    "    def _read_cofactor_info(self, cofactor_list_path, cofactor_pair_path):\n",
    "        \"\"\"Read in cofactor information, store so that reactants can be accurately mapped later\n",
    "        :return: cofactor_name_dict (all cofactors)\n",
    "        :rtype: {name in rxn rule: [names of molfile]}\n",
    "        :return: cofactor_list_dict (cofactor list)\n",
    "        :rtype: {cofactor: [names of molfile]}\n",
    "        :return: cofactor_pair_dict (cofactor pair)\n",
    "        :rtype: {cofactor1___cofactor2: [name of molfile1___name of molfile2]}\n",
    "        \"\"\"\n",
    "\n",
    "        cofactor_name_dict = {}\n",
    "        cofactor_list_dict = {}\n",
    "        cofactor_pair_dict = {}\n",
    "\n",
    "        cofactor_list_df = pd.read_csv(cofactor_list_path)\n",
    "        cofactor_pair_df = pd.read_csv(cofactor_pair_path)\n",
    "\n",
    "        # for each list\n",
    "        for i, current_df in cofactor_list_df.iterrows():\n",
    "            try:\n",
    "                cofactor_name_dict[current_df['replacement']].append(current_df['molfile'])\n",
    "            except KeyError:\n",
    "                cofactor_name_dict[current_df['replacement']] = [current_df['molfile']]\n",
    "            try:\n",
    "                cofactor_list_dict[current_df['replacement']].append(current_df['molfile'])\n",
    "            except KeyError:\n",
    "                cofactor_list_dict[current_df['replacement']] = [current_df['molfile']]\n",
    "\n",
    "        # for each pair\n",
    "        for i, current_df in cofactor_pair_df.iterrows():\n",
    "            try:\n",
    "                cofactor_name_dict[current_df['reactant_replacement']].append(current_df['reactant_molfile'])\n",
    "            except KeyError:\n",
    "                cofactor_name_dict[current_df['reactant_replacement']] = [current_df['reactant_molfile']]\n",
    "            try:\n",
    "                cofactor_pair_dict[\n",
    "                    current_df['reactant_replacement'] + '___' + current_df['product_replacement']].append(\n",
    "                    current_df['reactant_molfile'] + '___' + current_df['product_molfile'])\n",
    "            except KeyError:\n",
    "                cofactor_pair_dict[\n",
    "                    current_df['reactant_replacement'] + '___' + current_df['product_replacement']] =\\\n",
    "                    [current_df['reactant_molfile'] + '___' + current_df['product_molfile']]\n",
    "\n",
    "        # unique molfile name\n",
    "        for k, v in cofactor_name_dict.items():\n",
    "            cofactor_name_dict[k] = sorted(list(set(v)))\n",
    "        for k, v in cofactor_pair_dict.items():\n",
    "            cofactor_pair_dict[k] = sorted(list(set(v)))\n",
    "\n",
    "        return cofactor_name_dict, cofactor_list_dict, cofactor_pair_dict\n",
    "\n",
    "    def map_pickaxe_rules(self, lhs_dict, rhs_dict, rule_current, return_reaction_center=False):\n",
    "\n",
    "        rxn_df = self.rules.loc[rule_current.split(';')[0]]\n",
    "        rule = rxn_df['SMARTS']\n",
    "        reactants = rxn_df['Reactants']\n",
    "        products = rxn_df['Products']\n",
    "\n",
    "        # remove cofactor, sanitize mols\n",
    "        lhs_list, rhs_list = self._process_substrates(lhs_dict, rhs_dict, rule_current)\n",
    "        print(lhs_list, rhs_list)\n",
    "\n",
    "        # match index with pickaxe\n",
    "        match_index = self._map_rules(rule, lhs_list, rhs_list, reactants, products, return_reaction_center)\n",
    "\n",
    "        return match_index\n",
    "\n",
    "    def _map_rules(self, rule, lhs, rhs, reactants, products, return_reaction_center):\n",
    "        \"\"\"Operator mapping\"\"\"\n",
    "\n",
    "        rxn = Chem.rdChemReactions.ReactionFromSmarts(rule)\n",
    "        reactants = reactants.split(';')\n",
    "        cofactor_index_reactants = [i for i, r in enumerate(reactants) if r != 'Any']\n",
    "\n",
    "        products = products.split(';')\n",
    "        cofactor_index_products = [i for i, p in enumerate(products) if p != 'Any']\n",
    "\n",
    "        # if number of reactants does not match reactant template\n",
    "        if len(lhs) > reactants.count('Any'):\n",
    "            repetitive_mols = set(lhs).intersection(set(rhs))\n",
    "\n",
    "            while repetitive_mols:\n",
    "                lhs.remove(sorted(repetitive_mols)[0])\n",
    "                rhs.remove(sorted(repetitive_mols)[0])\n",
    "                repetitive_mols = set(lhs).intersection(set(rhs))\n",
    "\n",
    "        lhs_set = set()\n",
    "        for lhs_perm in itertools.permutations(lhs):\n",
    "            lhs_set.add(lhs_perm)\n",
    "\n",
    "        for lhs_perm in lhs_set:\n",
    "            lhs_temp = list(lhs_perm)\n",
    "\n",
    "            for c in cofactor_index_reactants:\n",
    "                if self.molfiles_path:\n",
    "                    lhs_temp[c:c] = [Chem.MolToSmiles(Chem.MolFromMolFile(os.path.sep.join([self.molfiles_path, self.cofactor_name_dict[reactants[c]] + '.mol'])))]\n",
    "                elif self.seed_dict:\n",
    "                    lhs_temp[c:c] = [self.seed_dict[self.cofactor_name_dict[reactants[c]]]]\n",
    "\n",
    "            # pruned MetaCyc\n",
    "            try:\n",
    "                lhs_tuple = tuple([Chem.MolFromSmiles(i) for i in lhs_temp])\n",
    "                outputs = rxn.RunReactants(lhs_tuple)\n",
    "            except:\n",
    "                try:\n",
    "                    lhs_tuple = tuple([Chem.MolFromSmiles(i, sanitize=False) for i in lhs_temp])\n",
    "                    outputs = rxn.RunReactants(lhs_tuple)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "            # # pickaxe\n",
    "            # lhs_tuple_list = []\n",
    "            # for i in lhs_temp:\n",
    "            #     try:\n",
    "            #         temp_mol = Chem.MolFromSmiles(i)\n",
    "            #         temp_mol = AllChem.AddHs(temp_mol)\n",
    "            #         AllChem.Kekulize(temp_mol, clearAromaticFlags=True)\n",
    "            #     except:\n",
    "            #         temp_mol = Chem.MolFromSmiles(i, sanitize=False)\n",
    "            #     lhs_tuple_list.append(temp_mol)\n",
    "            # lhs_tuple = tuple(lhs_tuple_list)\n",
    "            # outputs = rxn.RunReactants(lhs_tuple)\n",
    "\n",
    "            for rxn_output in outputs:\n",
    "\n",
    "                rhs_run = [Chem.MolToSmiles(rhs_mols) for rhs_mols in rxn_output]\n",
    "                rhs_list = copy.deepcopy(rhs_run)\n",
    "\n",
    "                for c in cofactor_index_products:\n",
    "                    rhs_list.remove(rhs_run[c])\n",
    "\n",
    "                # for all tautomer possibilities of clean rhs\n",
    "                for rhs in postsanitize_smiles(rhs):\n",
    "                    rhs = list(rhs)\n",
    "\n",
    "                    for rhs_list in postsanitize_smiles(rhs_list):\n",
    "\n",
    "                        # pruned MetaCyc\n",
    "                        if sorted(list(rhs_list)) == sorted(rhs):\n",
    "                            # lhs_index = [int(np.where(np.argsort(lhs) == i)[0]) for i in np.argsort(lhs_perm)]\n",
    "                            # rhs_index = [int(np.where(np.argsort(rhs) == i)[0]) for i in np.argsort(rhs_list)]\n",
    "                            lhs_index = [lhs.index(i) for i in lhs_perm]\n",
    "                            rhs_index = [rhs.index(i) for i in rhs_list]\n",
    "\n",
    "                            # return atom index of reaction center\n",
    "                            if return_reaction_center:\n",
    "\n",
    "                                # try to append lhs reactants\n",
    "                                lhs_mols = []\n",
    "                                for l in lhs_perm:\n",
    "                                    lhs_mols.append(Chem.MolFromSmiles(l))\n",
    "                                    if not lhs_mols[-1]:\n",
    "                                        lhs_mols[-1] = Chem.MolFromSmiles(l, sanitize=False)\n",
    "\n",
    "                                smarts_list, _ = get_smarts(rule)\n",
    "                                smarts_list = [s for i, s in enumerate(smarts_list)\n",
    "                                               if i not in cofactor_index_reactants]\n",
    "\n",
    "                                # possible reaction center\n",
    "                                temp_lhs_match = [Chem.MolFromSmiles(l, sanitize=False).GetSubstructMatches(\n",
    "                                    Chem.MolFromSmarts(smarts_list[i])) for i, l in enumerate(lhs_perm)]\n",
    "                                reaction_center_set = [set(itertools.chain(*l)) for l in temp_lhs_match]\n",
    "                                lhs_all_matches = itertools.product(*temp_lhs_match)\n",
    "\n",
    "                                # for all possible reaction centers\n",
    "                                for lhs_match in lhs_all_matches:\n",
    "\n",
    "                                    # iterate over all reactants\n",
    "                                    for l_idx, match in enumerate(lhs_match):\n",
    "                                        for protect in reaction_center_set[l_idx] - set(match):\n",
    "                                            lhs_mols[l_idx].GetAtomWithIdx(protect).SetProp('_protected', '1')\n",
    "\n",
    "                                    # add cofactors\n",
    "                                    lhs_temp_mol = list(lhs_mols)\n",
    "                                    for c in cofactor_index_reactants:\n",
    "                                        if self.molfiles_path:\n",
    "                                            lhs_temp_mol[c:c] = [Chem.MolFromMolFile(os.path.sep.join(\n",
    "                                                [self.molfiles_path, self.cofactor_name_dict[reactants[c]] + '.mol']))]\n",
    "                                        elif self.seed_dict:\n",
    "                                            lhs_temp_mol[c:c] = [Chem.MolFromSmiles(\n",
    "                                                self.seed_dict[self.cofactor_name_dict[reactants[c]]])]\n",
    "\n",
    "                                    # for all possible reaction outcomes\n",
    "                                    for rhs_rxn in rxn.RunReactants(tuple(lhs_temp_mol)):\n",
    "\n",
    "                                        for rhs_smiles in postsanitize_smiles([Chem.MolToSmiles(r) for r in rhs_rxn]):\n",
    "\n",
    "                                            # found match\n",
    "                                            if tuple(r for i, r in enumerate(rhs_smiles)\n",
    "                                                     if i not in cofactor_index_products) == rhs_list:\n",
    "                                                return lhs_index, rhs_index, list(lhs_match)\n",
    "\n",
    "                                    # else remove protection\n",
    "                                    for l_idx, match in enumerate(lhs_match):\n",
    "                                        for deprotect in reaction_center_set[l_idx] - set(match):\n",
    "                                            lhs_mols[l_idx].GetAtomWithIdx(deprotect).ClearProp('_protected')\n",
    "\n",
    "                            else:\n",
    "                                return lhs_index, rhs_index\n",
    "\n",
    "                        # # pickaxe\n",
    "                        # if sorted(list(rhs_list)) == sorted(rhs):\n",
    "                        #     lhs_index = [int(np.where(np.argsort(lhs) == i)[0]) for i in np.argsort(lhs_perm)]\n",
    "                        #     rhs_index = [int(np.where(np.argsort(rhs) == i)[0]) for i in np.argsort(rhs_list)]\n",
    "                        #     return lhs_index, rhs_index\n",
    "\n",
    "        return None, None\n",
    "\n",
    "    def _post_process(self, enzyme_list):\n",
    "        \"\"\"Post processing\"\"\"\n",
    "\n",
    "        enzyme_list_temp = []\n",
    "\n",
    "        non_orphan_flag = False\n",
    "\n",
    "        for e in enzyme_list:\n",
    "            if 'ENZRXN' in e:\n",
    "                non_orphan_flag = True\n",
    "                continue\n",
    "\n",
    "        if non_orphan_flag:\n",
    "            for e in enzyme_list:\n",
    "                if 'ENZRXN' in e:\n",
    "                    enzyme_list_temp.append(e)\n",
    "            return enzyme_list_temp\n",
    "        else:\n",
    "            return enzyme_list\n",
    "\n",
    "    def _process_substrates(self, lhs_dict_temp, rhs_dict_temp, rule_current):\n",
    "        \"\"\"Process substrates\"\"\"\n",
    "\n",
    "        # check cofactor designation\n",
    "        rule_reactant_names = self.rules.loc[rule_current, 'Reactants']\n",
    "        rule_product_names = self.rules.loc[rule_current, 'Products']\n",
    "\n",
    "        reactant_names, product_names = label_cofactor(sorted(lhs_dict_temp), sorted(rhs_dict_temp), self.cofactor_list_dict, self.cofactor_pair_dict)\n",
    "        print('from label_cofactor', reactant_names, product_names)\n",
    "        if sorted(rule_reactant_names.split(';')) != sorted(reactant_names.split(';')) \\\n",
    "                or sorted(rule_product_names.split(';')) != sorted(product_names.split(';')):\n",
    "            raise ValueError('Cofactor designation error.')\n",
    "\n",
    "        # create list from dict\n",
    "        lhs_list = [lhs_dict_temp[k] for i, k in enumerate(sorted([k for k in lhs_dict_temp]))\n",
    "                    if reactant_names.split(';')[i] == 'Any']\n",
    "        rhs_list = [rhs_dict_temp[k] for i, k in enumerate(sorted([k for k in rhs_dict_temp]))\n",
    "                    if product_names.split(';')[i] == 'Any']\n",
    "\n",
    "        # sanitize\n",
    "        for i, m in enumerate(lhs_list):\n",
    "            try:\n",
    "                temp_mol = Chem.MolFromSmiles(m)\n",
    "                Chem.rdmolops.RemoveStereochemistry(temp_mol)\n",
    "                lhs_list[i] = Chem.MolToSmiles(temp_mol)\n",
    "            except:\n",
    "                temp_mol = Chem.MolFromSmiles(m, sanitize=False)\n",
    "                Chem.rdmolops.RemoveStereochemistry(temp_mol)\n",
    "                lhs_list[i] = Chem.MolToSmiles(temp_mol)\n",
    "\n",
    "        for i, m in enumerate(rhs_list):\n",
    "            try:\n",
    "                temp_mol = Chem.MolFromSmiles(m)\n",
    "                Chem.rdmolops.RemoveStereochemistry(temp_mol)\n",
    "                rhs_list[i] = Chem.MolToSmiles(temp_mol)\n",
    "            except:\n",
    "                temp_mol = Chem.MolFromSmiles(m, sanitize=False)\n",
    "                Chem.rdmolops.RemoveStereochemistry(temp_mol)\n",
    "                rhs_list[i] = Chem.MolToSmiles(temp_mol)\n",
    "\n",
    "        return lhs_list, rhs_list\n",
    "    \n",
    "def get_cofactors(input_cofactor_list_path, input_cofactor_pair_path):\n",
    "    \"\"\"Get cofactor list & pairs\"\"\"\n",
    "\n",
    "    # cofactor to cpd id dict\n",
    "    cofactor_name_dict = {}\n",
    "\n",
    "    # cofactor list name designation\n",
    "    cofactor_list_dict = {}\n",
    "    for k, v in pd.read_csv(input_cofactor_list_path, sep='\\t', index_col=0).iterrows():\n",
    "        cofactor_list_dict[k.upper()] = v['replacement']\n",
    "        if v['replacement'] not in cofactor_name_dict:\n",
    "            cofactor_name_dict[v['replacement']] = k\n",
    "\n",
    "    # cofactor pair name designation\n",
    "    cofactor_pair_dict = {}\n",
    "    with open(input_cofactor_pair_path) as f:\n",
    "        cofactor_pair_read_json = json.loads(f.read())\n",
    "    for k, v in cofactor_pair_read_json.items():\n",
    "        for pair in v:\n",
    "            cofactor_pair_dict[(pair[1].upper(), pair[2].upper())] = k\n",
    "            cofactor_pair_dict[(pair[2].upper(), pair[1].upper())] = '%s,%s' % (k.split(',')[1], k.split(',')[0])\n",
    "            if k.split(',')[0] not in cofactor_name_dict:\n",
    "                cofactor_name_dict[k.split(',')[0]] = pair[1]\n",
    "                cofactor_name_dict[k.split(',')[1]] = pair[2]\n",
    "\n",
    "    return cofactor_name_dict, cofactor_list_dict, cofactor_pair_dict\n",
    "\n",
    "def label_cofactor(input_reactant_molfile, input_product_molfile, cofactor_list, cofactor_pair):  # label cofactors\n",
    "    \"\"\"Label cofactors & cofator pairs for product & reactant names\"\"\"\n",
    "\n",
    "    # reactant & product names\n",
    "    reactant_molfile = [':'.join(m.upper().split(':')[0:max(1, len(m.split(':')) - 1)]) for m in input_reactant_molfile]\n",
    "    product_molfile = [':'.join(m.upper().split(':')[0:max(1, len(m.split(':')) - 1)]) for m in input_product_molfile]\n",
    "\n",
    "    # new substrate labels\n",
    "    reactant_names = ['Any'] * len(reactant_molfile)\n",
    "    product_names = ['Any'] * len(product_molfile)\n",
    "\n",
    "    # get cofactor pairs\n",
    "    for i_lhs, lhs in enumerate(reactant_molfile):\n",
    "        for i_rhs, rhs in enumerate(product_molfile):\n",
    "\n",
    "            # skip if already assigned\n",
    "            if product_names[i_rhs] != 'Any':\n",
    "                continue\n",
    "\n",
    "            # assign cofactor pair designation\n",
    "            try:\n",
    "                temp_pair = cofactor_pair[(lhs, rhs)]\n",
    "                reactant_names[i_lhs] = temp_pair.split(',')[0]\n",
    "                product_names[i_rhs] = temp_pair.split(',')[1]\n",
    "                break\n",
    "            except KeyError:\n",
    "                continue\n",
    "\n",
    "        # assign cofactor list if no cofactor pair assigned\n",
    "        if reactant_names[i_lhs] == 'Any':\n",
    "            try:\n",
    "                reactant_names[i_lhs] = cofactor_list[lhs]\n",
    "            except KeyError:\n",
    "                continue\n",
    "\n",
    "    # assign cofactor list for rhs\n",
    "    for i_rhs, rhs in enumerate(product_molfile):\n",
    "\n",
    "        # assign cofactor list if no cofactor pair assigned\n",
    "        if product_names[i_rhs] == 'Any':\n",
    "            try:\n",
    "                product_names[i_rhs] = cofactor_list[rhs]\n",
    "            except KeyError:\n",
    "                continue\n",
    "\n",
    "    return ';'.join(reactant_names), ';'.join(product_names)\n",
    "\n",
    "def postsanitize_smiles(smiles_list):\n",
    "    \"\"\"Postsanitize smiles after running SMARTS.\n",
    "    :returns tautomer list of list of smiles\"\"\"\n",
    "\n",
    "    sanitized_list = []\n",
    "    # tautomer_smarts = '[#6:1]1:[#6:2]:[#7H1X3:3]:[#6:4]:[#7H0X2:5]:1>>[#6:1]1:[#6:2]:[#7H0X2:3]:[#6:4]:[#7H1X3:5]:1'\n",
    "    tautomer_smarts = '[#7H1X3&a:1]:[#6&a:2]:[#7H0X2&a:3]>>[#7H0X2:1]:[#6:2]:[#7H1X3:3]'\n",
    "\n",
    "    for s in smiles_list:\n",
    "\n",
    "        temp_mol = Chem.MolFromSmiles(s, sanitize=False)\n",
    "\n",
    "        # # pickaxe\n",
    "        # temp_mol = Chem.rdmolops.RemoveHs(temp_mol)\n",
    "\n",
    "        aromatic_bonds = [i.GetIdx() for i in temp_mol.GetBonds() if i.GetBondType() == Chem.rdchem.BondType.AROMATIC]\n",
    "\n",
    "        for i in temp_mol.GetBonds():\n",
    "            if i.GetBondType() == Chem.rdchem.BondType.UNSPECIFIED:\n",
    "                i.SetBondType(Chem.rdchem.BondType.SINGLE)\n",
    "\n",
    "        try:\n",
    "            Chem.SanitizeMol(temp_mol)\n",
    "            Chem.rdmolops.RemoveStereochemistry(temp_mol)\n",
    "            temp_smiles = Chem.MolToSmiles(temp_mol)\n",
    "\n",
    "        except Exception as msg:\n",
    "            if 'Can\\'t kekulize mol' in str(msg):\n",
    "                # unkekulized_indices = [int(i) for i in str(msg).split('Unkekulized atoms: ')[1].split('.')[0].rstrip(' \\n').split(' ')]\n",
    "                pyrrole_indices = [i[0] for i in temp_mol.GetSubstructMatches(Chem.MolFromSmarts('n'))]\n",
    "\n",
    "                # indices to sanitize\n",
    "                # for s_i in set(unkekulized_indices).intersection(set(pyrrole_indices)):\n",
    "                for s_i in pyrrole_indices:\n",
    "                    temp_mol = Chem.MolFromSmiles(s, sanitize=False)\n",
    "                    if temp_mol.GetAtomWithIdx(s_i).GetNumExplicitHs() == 0:\n",
    "                        temp_mol.GetAtomWithIdx(s_i).SetNumExplicitHs(1)\n",
    "                    elif temp_mol.GetAtomWithIdx(s_i).GetNumExplicitHs() == 1:\n",
    "                        temp_mol.GetAtomWithIdx(s_i).SetNumExplicitHs(0)\n",
    "                    try:\n",
    "                        Chem.SanitizeMol(temp_mol)\n",
    "\n",
    "                        processed_pyrrole_indices = [i[0] for i in\n",
    "                                                     temp_mol.GetSubstructMatches(Chem.MolFromSmarts('n'))]\n",
    "                        processed_aromatic_bonds = [i.GetIdx() for i in\n",
    "                                                    temp_mol.GetBonds() if i.GetBondType() == Chem.rdchem.BondType.AROMATIC]\n",
    "                        if processed_pyrrole_indices != pyrrole_indices or aromatic_bonds != processed_aromatic_bonds:\n",
    "                            continue\n",
    "\n",
    "                        Chem.rdmolops.RemoveStereochemistry(temp_mol)\n",
    "                        temp_smiles = Chem.MolToSmiles(temp_mol)\n",
    "                        break\n",
    "                    except:\n",
    "                        continue\n",
    "                if 'temp_smiles' not in vars():\n",
    "                    Chem.rdmolops.RemoveStereochemistry(temp_mol)\n",
    "                    temp_smiles = Chem.MolToSmiles(temp_mol)\n",
    "                    sanitized_list.append([temp_smiles])\n",
    "                    continue\n",
    "            else:\n",
    "                Chem.rdmolops.RemoveStereochemistry(temp_mol)\n",
    "                temp_smiles = Chem.MolToSmiles(temp_mol)\n",
    "                sanitized_list.append([temp_smiles])\n",
    "                continue\n",
    "        rxn = AllChem.ReactionFromSmarts(tautomer_smarts)\n",
    "\n",
    "        try:\n",
    "            tautomer_mols = rxn.RunReactants((Chem.MolFromSmiles(temp_smiles), ))\n",
    "        except:\n",
    "            try:\n",
    "                tautomer_mols = rxn.RunReactants((Chem.MolFromSmiles(temp_smiles, sanitize=False),))\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        tautomer_smiles = [Chem.MolToSmiles(m[0]) for m in tautomer_mols]\n",
    "        sanitized_list.append(sorted(set(tautomer_smiles + [temp_smiles])))\n",
    "\n",
    "    return list(itertools.product(*sanitized_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# initialize reaction mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cpd_path = 'brenda_neutralize.tsv'\n",
    "rules_path = 'minimal1224_all_uniprot.tsv'\n",
    "#rules_path = 'JN3604IMT_rules.tsv'\n",
    "cofactor_list_path = 'cofactor_list_alldb.tsv'\n",
    "cofactor_pair_path = 'cofactor_pair_alldb.json'\n",
    "SEED_neutralized = 'SEED_neutralized.tsv'\n",
    "db_cpd_dict = {k: v['smiles'] for k, v in pd.read_csv(cpd_path, sep='\\t', index_col=0).iterrows()}\n",
    "mapper = MapRules(rules_path=rules_path, cofactor_list_path=cofactor_list_path, cofactor_pair_path=cofactor_pair_path, seed_dict=db_cpd_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from label_cofactor NADH_CoF;O2;Any WATER;NAD_CoF;Any\n",
      "['CCC1OC(=O)C(C)C(O)C(C)C(O)C(C)CC(C)C(=O)C(C)C(O)C1C'] ['CCC1OC(=O)C(C)C(O)C(C)C(O)C(C)(O)CC(C)C(=O)C(C)C(O)C1C']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [11:13:02] Explicit valence for atom # 4 C, 5, is greater than permitted\n",
      "RDKit ERROR: [11:13:02] Explicit valence for atom # 4 C, 5, is greater than permitted\n",
      "RDKit ERROR: [11:13:02] Explicit valence for atom # 4 C, 5, is greater than permitted\n",
      "[11:13:02] Explicit valence for atom # 4 C, 5, is greater than permitted\n",
      "RDKit ERROR: [11:13:02] Explicit valence for atom # 4 C, 5, is greater than permitted\n",
      "[11:13:02] Explicit valence for atom # 4 C, 5, is greater than permitted\n",
      "[11:13:02] Explicit valence for atom # 4 C, 5, is greater than permitted\n",
      "[11:13:02] Explicit valence for atom # 4 C, 5, is greater than permitted\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0], [0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Reactants\n",
    "Deoxyerythronolide_SMILES = 'CCC1OC(=O)C(C)C(O)C(C)C(O)C(C)CC(C)C(=O)C(C)C(O)C1C'\n",
    "\n",
    "Deoxyerythronolide_SEED_ID = 'cpd02075:0'\n",
    "\n",
    "oxygen_smiles = 'O=O'\n",
    "oxygen_SEED_ID = 'cpd00007:0'\n",
    "\n",
    "NADH_smiles = 'NC(=O)C1=CN([C@@H]2O[C@H](COP(=O)(O)OP(=O)(O)OC[C@H]3O[C@@H](n4cnc5c(N)ncnc54)[C@H](OP(=O)(O)O)[C@@H]3O)[C@@H](O)[C@H]2O)C=CC1'\n",
    "NADH_SEED_ID = 'cpd00004:0'\n",
    "\n",
    "### Products\n",
    "erythronolide_SMILES = 'CCC1OC(=O)C(C)C(O)C(C)C(O)C(C)(O)CC(C)C(=O)C(C)C(O)C1C'\n",
    "\n",
    "erythronolide_SEED_ID = 'cpd04039:0'\n",
    "\n",
    "water_SMILES = 'O'\n",
    "water_SEED_ID = 'cpd00001:0'\n",
    "\n",
    "NAD_SEED_ID = 'cpd00003:0'\n",
    "NAD_SMILES = 'NC(=O)c1ccc[n+]([C@@H]2O[C@H](COP(=O)(O)OP(=O)(O)OC[C@H]3O[C@@H](n4cnc5c(N)ncnc54)[C@H](OP(=O)(O)O)[C@@H]3O)[C@@H](O)[C@H]2O)c1'\n",
    "\n",
    "rxn_dict = {'R0001':\n",
    "            [\n",
    "                ### Reactants dictionary\n",
    "                {Deoxyerythronolide_SEED_ID:Deoxyerythronolide_SMILES,\n",
    "                 NADH_SEED_ID:NADH_smiles,\n",
    "                 oxygen_SEED_ID:oxygen_smiles},\n",
    "\n",
    "                ### Products dictionary\n",
    "                {erythronolide_SEED_ID:erythronolide_SMILES,\n",
    "                 NAD_SEED_ID:NAD_SMILES,\n",
    "                 water_SEED_ID:water_SMILES}]}\n",
    "\n",
    "lhs_rhs = rxn_dict['R0001']\n",
    "mapper.map_pickaxe_rules(lhs_rhs[0], lhs_rhs[1], 'rule0004')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SEED_neutralized_df = pd.read_csv('SEED_neutralized.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# dict to store all reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rxn_dict = {'R00465': \n",
    "            [{'cpd00006:0': 'NC(=O)c1ccc[n+]([C@@H]2O[C@H](COP(=O)(O)OP(=O)(O)OC[C@H]3O[C@@H](n4cnc5c(N)ncnc54)[C@H](OP(=O)(O)O)[C@@H]3O)[C@@H](O)[C@H]2O)c1', 'cpd00139:0': 'O=C(O)CO'},\n",
    "             {'cpd00005:0': 'NC(=O)C1=CN([C@@H]2O[C@H](COP(=O)(O)OP(=O)(O)OC[C@H]3O[C@@H](n4cnc5c(N)ncnc54)[C@H](OP(=O)(O)O)[C@@H]3O)[C@@H](O)[C@H]2O)C=CC1', 'cpd00040:0': 'O=CC(=O)O'},\n",
    "             'rule0002']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cpd00006:0': 'NC(=O)c1ccc[n+]([C@@H]2O[C@H](COP(=O)(O)OP(=O)(O)OC[C@H]3O[C@@H](n4cnc5c(N)ncnc54)[C@H](OP(=O)(O)O)[C@@H]3O)[C@@H](O)[C@H]2O)c1',\n",
       " 'cpd00139:0': 'O=C(O)CO'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lhs_rhs = rxn_dict['R00465']\n",
    "lhs_rhs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cpd00005:0': 'NC(=O)C1=CN([C@@H]2O[C@H](COP(=O)(O)OP(=O)(O)OC[C@H]3O[C@@H](n4cnc5c(N)ncnc54)[C@H](OP(=O)(O)O)[C@@H]3O)[C@@H](O)[C@H]2O)C=CC1',\n",
       " 'cpd00040:0': 'O=CC(=O)O'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lhs_rhs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cpd00006:0': 'NC(=O)c1ccc[n+]([C@@H]2O[C@H](COP(=O)(O)OP(=O)(O)OC[C@H]3O[C@@H](n4cnc5c(N)ncnc54)[C@H](OP(=O)(O)O)[C@@H]3O)[C@@H](O)[C@H]2O)c1',\n",
       " 'cpd00139:0': 'O=C(O)CO'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lhs_rhs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### Reactants\n",
    "Deoxyerythronolide_SMILES = 'CCC1OC(=O)C(C)C(O)C(C)C(O)C(C)CC(C)C(=O)C(C)C(O)C1C'\n",
    "\n",
    "Deoxyerythronolide_SEED_ID = 'cpd02075:0'\n",
    "\n",
    "oxygen_smiles = 'O=O'\n",
    "oxygen_SEED_ID = 'cpd00007:0'\n",
    "\n",
    "NADH_smiles = 'NC(=O)C1=CN([C@@H]2O[C@H](COP(=O)(O)OP(=O)(O)OC[C@H]3O[C@@H](n4cnc5c(N)ncnc54)[C@H](OP(=O)(O)O)[C@@H]3O)[C@@H](O)[C@H]2O)C=CC1'\n",
    "NADH_SEED_ID = 'cpd00004:0'\n",
    "\n",
    "### Products\n",
    "erythronolide_SMILES = 'CCC1OC(=O)C(C)C(O)C(C)C(O)C(C)(O)CC(C)C(=O)C(C)C(O)C1C'\n",
    "\n",
    "erythronolide_SEED_ID = 'cpd04039:0'\n",
    "\n",
    "water_SMILES = 'O'\n",
    "water_SEED_ID = 'cpd00001:0'\n",
    "\n",
    "NAD_SEED_ID = 'cpd00003:0'\n",
    "NAD_SMILES = 'NC(=O)c1ccc[n+]([C@@H]2O[C@H](COP(=O)(O)OP(=O)(O)OC[C@H]3O[C@@H](n4cnc5c(N)ncnc54)[C@H](OP(=O)(O)O)[C@@H]3O)[C@@H](O)[C@H]2O)c1'\n",
    "\n",
    "rxn_dict = {'R0001':\n",
    "            [\n",
    "                ### Reactants dictionary\n",
    "                {Deoxyerythronolide_SEED_ID:Deoxyerythronolide_SMILES,\n",
    "                 NADH_SEED_ID:NADH_smiles,\n",
    "                 oxygen_SEED_ID:oxygen_smiles},\n",
    "\n",
    "                ### Products dictionary\n",
    "                {erythronolide_SEED_ID:erythronolide_SMILES,\n",
    "                 NAD_SEED_ID:NAD_SMILES,\n",
    "                 water_SEED_ID:water_SMILES}]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def map_rxn_to_rule(lhs_rhs):\n",
    "    count = 0\n",
    "    for i in range(0,2000):\n",
    "\n",
    "        count += 1\n",
    "        if count<10:\n",
    "            rule = 'rule000%i'%count\n",
    "        elif count >=10 and count<100:\n",
    "            rule = 'rule00%i'%count\n",
    "        elif count >=100 and count<1000:\n",
    "            rule = 'rule0%i'%count\n",
    "        else:\n",
    "            rule = 'rule%i'%count\n",
    "\n",
    "        try:\n",
    "            mapping_object = mapper.map_pickaxe_rules(lhs_rhs[0], lhs_rhs[1],rule)\n",
    "            if mapping_object[0][0] == 0 and mapping_object[1][0] == 0:\n",
    "                break\n",
    "        except ValueError: # exception for specific error type\n",
    "            pass\n",
    "\n",
    "    return rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "mapped reaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from label_cofactor NADH_CoF;O2;Any WATER;NAD_CoF;Any\n",
      "from label_cofactor NADH_CoF;O2;Any WATER;NAD_CoF;Any\n",
      "from label_cofactor NADH_CoF;O2;Any WATER;NAD_CoF;Any\n",
      "from label_cofactor NADH_CoF;O2;Any WATER;NAD_CoF;Any\n",
      "['CCC1OC(=O)C(C)C(O)C(C)C(O)C(C)CC(C)C(=O)C(C)C(O)C1C'] ['CCC1OC(=O)C(C)C(O)C(C)C(O)C(C)(O)CC(C)C(=O)C(C)C(O)C1C']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [11:23:55] Explicit valence for atom # 4 C, 5, is greater than permitted\n",
      "RDKit ERROR: [11:23:55] Explicit valence for atom # 4 C, 5, is greater than permitted\n",
      "RDKit ERROR: [11:23:55] Explicit valence for atom # 4 C, 5, is greater than permitted\n",
      "RDKit ERROR: [11:23:55] Explicit valence for atom # 4 C, 5, is greater than permitted\n",
      "[11:23:55] Explicit valence for atom # 4 C, 5, is greater than permitted\n",
      "[11:23:55] Explicit valence for atom # 4 C, 5, is greater than permitted\n",
      "[11:23:55] Explicit valence for atom # 4 C, 5, is greater than permitted\n",
      "[11:23:55] Explicit valence for atom # 4 C, 5, is greater than permitted\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'rule0004'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lhs_rhs = rxn_dict['R0001']\n",
    "map_rxn_to_rule(lhs_rhs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lhs_rhs = rxn_dict['R0001']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello ['CCC1OC(=O)C(C)C(O)C(C)C(O)C(C)CC(C)C(=O)C(C)C(O)C1C']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [16:59:06] Explicit valence for atom # 4 C, 5, is greater than permitted\n",
      "RDKit ERROR: [16:59:06] Explicit valence for atom # 4 C, 5, is greater than permitted\n",
      "[16:59:06] Explicit valence for atom # 4 C, 5, is greater than permitted\n",
      "[16:59:06] Explicit valence for atom # 4 C, 5, is greater than permitted\n",
      "RDKit ERROR: [16:59:06] Explicit valence for atom # 4 C, 5, is greater than permitted\n",
      "RDKit ERROR: [16:59:06] Explicit valence for atom # 4 C, 5, is greater than permitted\n",
      "[16:59:06] Explicit valence for atom # 4 C, 5, is greater than permitted\n",
      "[16:59:06] Explicit valence for atom # 4 C, 5, is greater than permitted\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0], [0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapper.map_pickaxe_rules(lhs_rhs[0], lhs_rhs[1], 'rule0004')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mapper' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/g7/7p1djmms7lxdrm3nk5jjxs680000gn/T/ipykernel_1310/2705074207.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_pickaxe_rules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlhs_rhs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlhs_rhs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rule0002'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mapper' is not defined"
     ]
    }
   ],
   "source": [
    "mapper.map_pickaxe_rules(lhs_rhs[0], lhs_rhs[1], 'rule0002')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0], [0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [15:57:30] Explicit valence for atom # 1 C, 5, is greater than permitted\n",
      "RDKit ERROR: [15:57:30] Explicit valence for atom # 1 C, 5, is greater than permitted\n"
     ]
    }
   ],
   "source": [
    "print(mapper.map_pickaxe_rules(lhs_rhs[0], lhs_rhs[1], 'rule0002'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "unmapped reaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [16:27:23] Explicit valence for atom # 1 C, 5, is greater than permitted\n",
      "RDKit ERROR: [16:27:23] Explicit valence for atom # 1 C, 5, is greater than permitted\n",
      "RDKit ERROR: [16:27:23] Explicit valence for atom # 1 C, 5, is greater than permitted\n",
      "RDKit ERROR: [16:27:23] Explicit valence for atom # 1 C, 5, is greater than permitted\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(mapper.map_pickaxe_rules(lhs_rhs[0], lhs_rhs[1], 'rule0018'))==None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ValueError if cofactor not matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cofactor designation error.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d8b81c3ca2bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_pickaxe_rules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlhs_rhs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlhs_rhs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rule0001'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-067494317c25>\u001b[0m in \u001b[0;36mmap_pickaxe_rules\u001b[0;34m(self, lhs_dict, rhs_dict, rule_current, return_reaction_center)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;31m# remove cofactor, sanitize mols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0mlhs_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_substrates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlhs_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrule_current\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;31m# match index with pickaxe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-067494317c25>\u001b[0m in \u001b[0;36m_process_substrates\u001b[0;34m(self, lhs_dict_temp, rhs_dict_temp, rule_current)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrule_reactant_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreactant_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrule_product_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproduct_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cofactor designation error.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0;31m# create list from dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cofactor designation error."
     ]
    }
   ],
   "source": [
    "print(mapper.map_pickaxe_rules(lhs_rhs[0], lhs_rhs[1], 'rule0001'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Yash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "table6_filepath = \"/Users/yashchainani96/PycharmProjects/enzyme_substrate_data/table6_reactants_and_products.json\"\n",
    "table7_filepath = \"/Users/yashchainani96/PycharmProjects/enzyme_substrate_data/table7_reactants_and_products.json\"\n",
    "table8_filepath = \"/Users/yashchainani96/PycharmProjects/enzyme_substrate_data/table8_reactants_and_products.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(table6_filepath, 'r') as j:\n",
    "     table6_dict = json.loads(j.read())\n",
    "with open(table7_filepath, 'r') as j:\n",
    "     table7_dict = json.loads(j.read())\n",
    "with open(table8_filepath,'r') as j:\n",
    "     table8_dict = json.loads(j.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def reformat_dict(current_dict): # add in neutralization\n",
    "                                # Get rid of H+ (cpd00067)\n",
    "                                # compound IDs are five digits and rule IDs are four digits\n",
    "                                # tables 6 and 8\n",
    "    rxn_count = 0\n",
    "    reformatted_dict = {}\n",
    "    \n",
    "    for i in range(0,132):\n",
    "        \n",
    "        rxn_count += 1\n",
    "        key = 'R%i'%rxn_count\n",
    "        value = list([])\n",
    "        num_reactants = len(current_dict['Reaction %i Reactant ID'%i][0])\n",
    "        num_products = len(current_dict['Reaction %i Products ID'%i][0])\n",
    "        \n",
    "        if num_reactants != 0 and num_products != 0: # ensure reactant and product list not empty\n",
    "            \n",
    "            reactant_dict = {} # initialize dict to store reactant info\n",
    "            product_dict = {} # initialize dict to store product info\n",
    "            \n",
    "            for k in range(0,num_reactants):\n",
    "                reactant_id = current_dict['Reaction %i Reactant ID'%i][0][0]\n",
    "                reactant_smiles = current_dict['Reaction %i Reactant smiles'%i][0][0]\n",
    "                reactant_dict.update({reactant_id:reactant_smiles})\n",
    "                \n",
    "            for j in range(0,num_products):\n",
    "                product_id = current_dict['Reaction %i Products ID'%i][0][0]\n",
    "                product_smiles = current_dict['Reaction %i Reactant smiles'%i][0]\n",
    "                product_dict.update({product_id:product_smiles})\n",
    "                \n",
    "            value.append(reactant_dict)\n",
    "            value.append(product_dict)\n",
    "            reformatted_dict.update({key:value})\n",
    "        \n",
    "    return reformatted_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def map_rxn_to_rule(lhs_rhs):\n",
    "    count = 0\n",
    "    for i in range(0,2000):\n",
    "        \n",
    "        count += 1\n",
    "        if count<10:\n",
    "            rule = 'rule000%i'%count\n",
    "        elif count >=10 and count<100:\n",
    "            rule = 'rule00%i'%count\n",
    "        elif count >=100 and count<1000:\n",
    "            rule = 'rule0%i'%count\n",
    "        else:\n",
    "            rule = 'rule%i'%count\n",
    "        \n",
    "        try:\n",
    "            mapping_object = mapper.map_pickaxe_rules(lhs_rhs[0], lhs_rhs[1],rule)\n",
    "            if mapping_object[0][0] == 0 and mapping_object[1][0] == 0:\n",
    "                break\n",
    "        except ValueError: # exception for specific error type\n",
    "            pass\n",
    "        \n",
    "    return rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Reaction 63 Reactant ID'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-6f406e4182fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreformatted_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreformat_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable8_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mreformatted_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-4ce0a6eb21ec>\u001b[0m in \u001b[0;36mreformat_dict\u001b[0;34m(current_dict)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'R%i'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mrxn_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mnum_reactants\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Reaction %i Reactant ID'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mnum_products\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Reaction %i Products ID'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Reaction 63 Reactant ID'"
     ]
    }
   ],
   "source": [
    "reformatted_dict = reformat_dict(table8_dict)\n",
    "reformatted_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reformatted_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-26e9727c6292>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlhs_rhs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreformatted_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'R28'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_rxn_to_rule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlhs_rhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'reformatted_dict' is not defined"
     ]
    }
   ],
   "source": [
    "lhs_rhs = reformatted_dict['R28']\n",
    "rule = map_rxn_to_rule(lhs_rhs)\n",
    "rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for key in reformatted_dict.keys():\n",
    "    lhs_rhs = reformatted_dict[key]\n",
    "    map_rxn_to_rule(lhs_rhs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rxn_dict = {'R00465': \n",
    "            [{'cpd00006:0': 'NC(=O)c1ccc[n+]([C@@H]2O[C@H](COP(=O)(O)OP(=O)(O)OC[C@H]3O[C@@H](n4cnc5c(N)ncnc54)[C@H](OP(=O)(O)O)[C@@H]3O)[C@@H](O)[C@H]2O)c1', 'cpd00139:0': 'O=C(O)CO'},\n",
    "             {'cpd00005:0': 'NC(=O)C1=CN([C@@H]2O[C@H](COP(=O)(O)OP(=O)(O)OC[C@H]3O[C@@H](n4cnc5c(N)ncnc54)[C@H](OP(=O)(O)O)[C@@H]3O)[C@@H](O)[C@H]2O)C=CC1', 'cpd00040:0': 'O=CC(=O)O'},\n",
    "             'rule0002']}\n",
    "\n",
    "### dictionary structure\n",
    "{'reaction number':[{'reactant_1_id':'reactant_1_smiles','reactant_2_id':'reactant_2_smiles'}.\n",
    "                    {'product_1_id':'product_1_smiles','product_2_id':'product_2_smiles'},\n",
    "                    'rule to try (iterable)']\n",
    "}\n",
    "\n",
    "### ALWAYS REMOVE cpd00067 H+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "table7_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reactant_smiles = table7_dict['Reaction 0 Reactant smiles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rxn_dict = {'R00465': \n",
    "            [{'cpd00006:0': 'NC(=O)c1ccc[n+]([C@@H]2O[C@H](COP(=O)(O)OP(=O)(O)OC[C@H]3O[C@@H](n4cnc5c(N)ncnc54)[C@H](OP(=O)(O)O)[C@@H]3O)[C@@H](O)[C@H]2O)c1', 'cpd00139:0': 'O=C(O)CO'},\n",
    "             {'cpd00005:0': 'NC(=O)C1=CN([C@@H]2O[C@H](COP(=O)(O)OP(=O)(O)OC[C@H]3O[C@@H](n4cnc5c(N)ncnc54)[C@H](OP(=O)(O)O)[C@@H]3O)[C@@H](O)[C@H]2O)C=CC1', 'cpd00040:0': 'O=CC(=O)O'},\n",
    "             'rule0002']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def remove_hydrogen_ions(rxn_dict)\n",
    "    for key in rxn_dict.keys():\n",
    "        reactants = rxn_dict[key][0]\n",
    "        products = rxn_dict[key][1]\n",
    "        if 'cpd00067:0' in reactants.keys():\n",
    "            del reactants['cpd00067']\n",
    "        \n",
    "        if 'cpd00067:0' in products.keys():\n",
    "            del products['cpd00067']\n",
    "    return rxn_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('mine')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "fa06f199a73c4c009ddbae00eb3047470ee8a1f069b7c2a44a76d0753876d9a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
